{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet with pytorch\n",
    "\n",
    "- load data\n",
    "- build model\n",
    "- train and test\n",
    "- transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        shape = torch.prod(torch.tensor(x.shape[1:])).item()\n",
    "        return x.view(-1, shape)\n",
    "        \n",
    "def plot_image(img, label, name):\n",
    "    fig = plt.figure()\n",
    "    for i in range(6):\n",
    "        plt.subplot(2,3,i+1)\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(img[1][0]*0.3081 + 0.1307, cmap='gray', interpolation='none')\n",
    "        plt.title(\"{}:{}\".format(name, label[i].item()))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  os, glob\n",
    "import  random, csv\n",
    "from    torch.utils.data import Dataset, DataLoader\n",
    "from    torchvision import transforms\n",
    "from    PIL import Image\n",
    "\n",
    "class Pokemon(Dataset):\n",
    "    def __init__(self, root, resize, mode):\n",
    "        super(Pokemon, self).__init__()\n",
    "        \n",
    "        self.root = root\n",
    "        self.resize = resize\n",
    "        \n",
    "        self.name2label = {}\n",
    "        for name in sorted(os.listdir(os.path.join(root))):\n",
    "            if not os.path.isdir(os.path.join(root, name)):\n",
    "                continue\n",
    "            \n",
    "            self.name2label[name] = len(self.name2label.keys())\n",
    "        \n",
    "        self.images, self.labels = self.load_csv('images.csv')\n",
    "        \n",
    "        if mode == 'train':\n",
    "            self.images = self.images[:int(0.6*len(self.images))]\n",
    "            self.labels = self.labels[:int(0.6*len(self.labels))]\n",
    "        elif mode == 'val':\n",
    "            self.images = self.images[int(0.6*len(self.images)):int(0.8*len(self.images))]\n",
    "            self.labels = self.labels[int(0.6*len(self.labels)):int(0.8*len(self.labels))]\n",
    "        elif mode == 'test':\n",
    "            self.images = self.images[int(0.8*len(self.images)):]\n",
    "            self.labels = self.labels[int(0.8*len(self.labels)):]\n",
    "    \n",
    "    def load_csv(self, filename):\n",
    "        if not os.path.exists(os.path.join(self.root, filename)):\n",
    "            images = []\n",
    "            for name in self.name2label.keys():\n",
    "                images += glob.glob(os.path.join(self.root, name, '*.png'))\n",
    "                images += glob.glob(os.path.join(self.root, name, '*.jpg'))\n",
    "                images += glob.glob(os.path.join(self.root, name, '*.jpeg'))\n",
    "            random.shuffle(images)\n",
    "            with open(os.path.join(self.root, filename), mode='w', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                for img in images:\n",
    "                    name = img.split(os.sep)[-2]\n",
    "                    label = self.name2label[name]\n",
    "                    writer.writerow([img,label])\n",
    "                print('writen into csv file:', filename)\n",
    "                \n",
    "        images, labels = [], []\n",
    "        with open(os.path.join(self.root, filename)) as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                img,label = row\n",
    "                label = int(label)\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "        assert len(images) == len(labels)\n",
    "        return images, labels\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def denormalize(self, x_hat):\n",
    "        \n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        # x_hat = (x-mean)/std\n",
    "        # x = x_hat*std = mean\n",
    "        # x: [c, h, w]\n",
    "        # mean: [3] => [3, 1, 1]\n",
    "        mean = torch.tensor(mean).unsqueeze(1).unsqueeze(1)\n",
    "        std = torch.tensor(std).unsqueeze(1).unsqueeze(1)\n",
    "        # print(mean.shape, std.shape)\n",
    "        x = x_hat * std + mean\n",
    "        return x\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.images[idx], self.labels[idx]\n",
    "        tf = transforms.Compose([\n",
    "            lambda x:Image.open(x).convert('RGB'), # string path= > image data\n",
    "            transforms.Resize((int(self.resize*1.25), int(self.resize*1.25))),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.CenterCrop(self.resize),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        img = tf(img)\n",
    "        label = torch.tensor(label)\n",
    "        return img,label\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "from    torch.nn import functional as F\n",
    "class ResBlk(nn.Module):\n",
    "    def __init__(self, inChannel, outChannel, stride=1):\n",
    "        super(ResBlk, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inChannel, outChannel, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(outChannel)\n",
    "        self.conv2 = nn.Conv2d(outChannel, outChannel, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(outChannel)\n",
    "        \n",
    "        self.extra = nn.Sequential()\n",
    "        if outChannel!=inChannel:\n",
    "            self.extra = nn.Sequential(\n",
    "            nn.Conv2d(inChannel, outChannel, kernel_size=1, stride=stride),\n",
    "            nn.BatchNorm2d(outChannel))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.extra(x) + out\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "        nn.Conv2d(3,16,kernel_size=3,stride=3,padding=0),\n",
    "        nn.BatchNorm2d(16))\n",
    "        \n",
    "        self.blk1 = ResBlk(16,32,stride=3)\n",
    "        self.blk2 = ResBlk(32,64,stride=3)\n",
    "        self.blk3 = ResBlk(64,128,stride=2)\n",
    "        self.blk4 = ResBlk(128,256,stride=2)\n",
    "        \n",
    "        self.outlayer = nn.Linear(256*3*3, num_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.blk1(x)\n",
    "        x = self.blk2(x)\n",
    "        x = self.blk3(x)\n",
    "        x = self.blk4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.outlayer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5182881355285645 0\n",
      "2.103452205657959 1\n",
      "2.068197727203369 2\n",
      "1.9896528720855713 3\n",
      "2.0654709339141846 4\n",
      "0.7708738446235657 5\n",
      "2.038616180419922 6\n",
      "0.6397014856338501 7\n",
      "0.9876345992088318 8\n",
      "0.882544994354248 9\n",
      "1.1049165725708008 10\n",
      "0.6454030275344849 11\n",
      "0.9028308391571045 12\n",
      "0.7742918133735657 13\n",
      "0.46328219771385193 14\n",
      "0.5010548233985901 15\n",
      "0.9106078147888184 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/striverwang/anaconda3/envs/dl/lib/python3.7/site-packages/PIL/Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26927223801612854 17\n",
      "0.2981182336807251 18\n",
      "0.9401915669441223 19\n",
      "0.8364970088005066 20\n",
      "0.8666273951530457 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/striverwang/anaconda3/envs/dl/lib/python3.7/site-packages/PIL/Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n",
      "/Users/striverwang/anaconda3/envs/dl/lib/python3.7/site-packages/PIL/Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20236420631408691 22\n",
      "0.5642319321632385 23\n",
      "0.6349573135375977 24\n",
      "0.40248703956604004 25\n",
      "0.4329265058040619 26\n",
      "0.6033247113227844 27\n",
      "0.8497241735458374 28\n",
      "0.3229106068611145 29\n",
      "0.26927077770233154 30\n",
      "0.19804391264915466 31\n",
      "0.15070338547229767 32\n",
      "0.6603262424468994 33\n",
      "0.3132723569869995 34\n",
      "0.3251098394393921 35\n",
      "0.3701622784137726 36\n",
      "0.5432785153388977 37\n",
      "1.3515344858169556 38\n",
      "0.9648956060409546 39\n",
      "0.6611078381538391 40\n",
      "0.5435547232627869 41\n",
      "0.662379801273346 42\n",
      "0.2745145559310913 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/striverwang/anaconda3/envs/dl/lib/python3.7/site-packages/PIL/Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44152846932411194 44\n",
      "0.5021432042121887 45\n",
      "0.28868770599365234 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/striverwang/anaconda3/envs/dl/lib/python3.7/site-packages/PIL/Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41890308260917664 47\n",
      "0.17976997792720795 48\n",
      "0.2890416383743286 49\n",
      "0.19006359577178955 50\n",
      "0.3342059850692749 51\n",
      "0.34223130345344543 52\n",
      "0.301426500082016 53\n",
      "0.47043895721435547 54\n",
      "0.4641607701778412 55\n",
      "0.6855977773666382 56\n",
      "0.4535382091999054 57\n",
      "0.21803301572799683 58\n",
      "0.19373226165771484 59\n",
      "0.4124784469604492 60\n",
      "0.39980462193489075 61\n",
      "0.14749546349048615 62\n",
      "0.2610394358634949 63\n",
      "0.19463536143302917 64\n",
      "0.37893179059028625 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/striverwang/anaconda3/envs/dl/lib/python3.7/site-packages/PIL/Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1933976709842682 66\n",
      "0.2926105856895447 67\n",
      "0.3652646541595459 68\n",
      "0.20480839908123016 69\n",
      "0.2366904616355896 70\n",
      "0.11189503222703934 71\n",
      "0.08500628173351288 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/striverwang/anaconda3/envs/dl/lib/python3.7/site-packages/PIL/Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8213914036750793 73\n",
      "0.3684108555316925 74\n",
      "0.1268329918384552 75\n",
      "0.2117617428302765 76\n",
      "0.2701195478439331 77\n",
      "0.07751460373401642 78\n",
      "0.15555301308631897 79\n",
      "0.2562590539455414 80\n",
      "0.16732099652290344 81\n",
      "0.3893750011920929 82\n",
      "0.10876034945249557 83\n",
      "0.19097016751766205 84\n",
      "0.15446113049983978 85\n",
      "0.4122318923473358 86\n",
      "0.3321864604949951 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/striverwang/anaconda3/envs/dl/lib/python3.7/site-packages/PIL/Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30623143911361694 88\n",
      "0.19131679832935333 89\n",
      "0.09633930027484894 90\n",
      "0.2454959899187088 91\n",
      "0.13489826023578644 92\n",
      "0.20842348039150238 93\n",
      "0.11459426581859589 94\n",
      "0.14208580553531647 95\n",
      "0.11801980435848236 96\n",
      "0.0648353323340416 97\n",
      "0.10164263844490051 98\n",
      "0.1570172905921936 99\n",
      "0.31430909037590027 100\n",
      "0.30121222138404846 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/striverwang/anaconda3/envs/dl/lib/python3.7/site-packages/PIL/Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1856570690870285 102\n",
      "0.22559285163879395 103\n",
      "0.17752188444137573 104\n",
      "0.1566973626613617 105\n",
      "0.3598528504371643 106\n",
      "0.21164388954639435 107\n",
      "0.06415168195962906 108\n",
      "0.115009605884552 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/striverwang/anaconda3/envs/dl/lib/python3.7/site-packages/PIL/Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3740781843662262 110\n",
      "0.04966244474053383 111\n",
      "0.16519340872764587 112\n",
      "0.25447380542755127 113\n",
      "0.02255323715507984 114\n",
      "0.22495262324810028 115\n",
      "0.02041688933968544 116\n",
      "0.2654249966144562 117\n",
      "0.14234080910682678 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/striverwang/anaconda3/envs/dl/lib/python3.7/site-packages/PIL/Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09890533983707428 119\n",
      "0.1089281290769577 120\n",
      "0.14453570544719696 121\n",
      "0.06562875956296921 122\n",
      "0.1481994092464447 123\n",
      "0.14144107699394226 124\n",
      "0.1803153157234192 125\n",
      "0.10038936883211136 126\n",
      "0.24415309727191925 127\n",
      "0.022119730710983276 128\n",
      "0.3638387620449066 129\n",
      "0.4302480220794678 130\n",
      "0.26322466135025024 131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/striverwang/anaconda3/envs/dl/lib/python3.7/site-packages/PIL/Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051636502146720886 132\n",
      "0.1825401484966278 133\n",
      "0.28560659289360046 134\n",
      "0.025978052988648415 135\n",
      "0.5876161456108093 136\n",
      "0.11468280851840973 137\n",
      "0.13202053308486938 138\n",
      "0.2746155261993408 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/striverwang/anaconda3/envs/dl/lib/python3.7/site-packages/PIL/Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20237937569618225 140\n",
      "0.05579480156302452 141\n",
      "0.1419968605041504 142\n",
      "0.044787876307964325 143\n",
      "0.13735675811767578 144\n",
      "0.07284069806337357 145\n",
      "0.06625097990036011 146\n",
      "0.48213109374046326 147\n",
      "0.21015653014183044 148\n",
      "0.5998139977455139 149\n",
      "0.07734183967113495 150\n",
      "0.13093870878219604 151\n",
      "0.0682600662112236 152\n",
      "0.21881122887134552 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/striverwang/anaconda3/envs/dl/lib/python3.7/site-packages/PIL/Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3889780044555664 154\n",
      "0.23757795989513397 155\n",
      "0.13890765607357025 156\n",
      "0.2523658871650696 157\n",
      "0.11367856711149216 158\n",
      "0.11287233233451843 159\n",
      "0.5022757053375244 160\n",
      "0.022356029599905014 161\n",
      "0.045778051018714905 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/striverwang/anaconda3/envs/dl/lib/python3.7/site-packages/PIL/Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35135412216186523 163\n",
      "0.13932223618030548 164\n",
      "0.03947664052248001 165\n",
      "0.429040789604187 166\n",
      "0.5030101537704468 167\n",
      "0.1739075779914856 168\n",
      "0.26843610405921936 169\n",
      "0.1280399113893509 170\n",
      "0.19253885746002197 171\n",
      "0.05064299330115318 172\n",
      "0.15613166987895966 173\n",
      "0.1485508233308792 174\n",
      "0.12354399263858795 175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/striverwang/anaconda3/envs/dl/lib/python3.7/site-packages/PIL/Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n",
      "/Users/striverwang/anaconda3/envs/dl/lib/python3.7/site-packages/PIL/Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23393459618091583 176\n",
      "0.21928325295448303 177\n",
      "0.16773898899555206 178\n",
      "0.14287392795085907 179\n",
      "0.21804362535476685 180\n",
      "0.10113179683685303 181\n",
      "0.005801535211503506 182\n",
      "0.045602116733789444 183\n",
      "0.14524514973163605 184\n",
      "0.017220256850123405 185\n",
      "0.031919315457344055 186\n",
      "0.11641865223646164 187\n",
      "0.0707625225186348 188\n",
      "0.39153528213500977 189\n",
      "0.8241366147994995 190\n",
      "0.07546449452638626 191\n",
      "0.049078069627285004 192\n",
      "0.15445783734321594 193\n",
      "0.21944354474544525 194\n",
      "0.02491134963929653 195\n",
      "0.027529647573828697 196\n",
      "0.03903251141309738 197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/striverwang/anaconda3/envs/dl/lib/python3.7/site-packages/PIL/Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11700162291526794 198\n",
      "0.1360456794500351 199\n",
      "0.07049642503261566 200\n",
      "0.06530829519033432 201\n",
      "0.13503466546535492 202\n",
      "0.13573579490184784 203\n",
      "0.3640984296798706 204\n",
      "0.20868128538131714 205\n",
      "0.06068388372659683 206\n",
      "0.4632214307785034 207\n",
      "0.10328789055347443 208\n",
      "0.4642248749732971 209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/striverwang/anaconda3/envs/dl/lib/python3.7/site-packages/PIL/Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33785462379455566 210\n",
      "0.11723791062831879 211\n",
      "0.02525440603494644 212\n",
      "0.11242695152759552 213\n",
      "0.04972611367702484 214\n",
      "0.22670121490955353 215\n",
      "1.3936501741409302 216\n",
      "0.1763879805803299 217\n",
      "0.1639140397310257 218\n",
      "0.06320852041244507 219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/striverwang/anaconda3/envs/dl/lib/python3.7/site-packages/PIL/Image.py:968: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_acc: 0.8755364806866953 best_epoch: 8\n",
      "test_acc: 0.8497854077253219\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim, nn\n",
    "import visdom\n",
    "batchsz = 32\n",
    "lr = 1e-3\n",
    "epochs = 10\n",
    "\n",
    "trainData = Pokemon('./data/pokemon', 224, mode='train')\n",
    "valData = Pokemon('./data/pokemon', 224, mode='val')\n",
    "testData = Pokemon('./data/pokemon', 224, mode='test')\n",
    "\n",
    "trainLoader = DataLoader(trainData, batch_size=batchsz, shuffle=True,\n",
    "                        num_workers=4)\n",
    "valLoader = DataLoader(valData, batch_size=batchsz, shuffle=False,\n",
    "                      num_workers=2)\n",
    "testLoader = DataLoader(testData, batch_size=batchsz, shuffle=False,\n",
    "                       num_workers=2)\n",
    "\n",
    "model = ResNet18(5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criteon = nn.CrossEntropyLoss()\n",
    "viz = visdom.Visdom()\n",
    "viz.line([0], [-1], win='loss', opts=dict(title='loss'))\n",
    "viz.line([0], [-1], win='val_acc', opts=dict(title='val_acc'))\n",
    "def evaluate(model, loader):\n",
    "    correct = 0\n",
    "    total = len(loader.dataset)\n",
    "    for x,y in loader:\n",
    "        with torch.no_grad():\n",
    "            logits = model(x)\n",
    "            pred = logits.argmax(dim=1)\n",
    "        correct += torch.eq(pred,y).sum().float().item()\n",
    "    return correct/total\n",
    "\n",
    "best_acc, best_epoch = 0,0\n",
    "global_step = 0\n",
    "for epoch in range(epochs):\n",
    "\n",
    "        for step, (x,y) in enumerate(trainLoader):\n",
    "            model.train()\n",
    "            logits = model(x)\n",
    "            loss = criteon(logits, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            viz.line([loss.item()], [global_step], win='loss', update='append')\n",
    "            print(loss.item(), global_step)\n",
    "            global_step += 1\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "\n",
    "            val_acc = evalute(model, valLoader)\n",
    "            if val_acc> best_acc:\n",
    "                best_epoch = epoch\n",
    "                best_acc = val_acc\n",
    "\n",
    "                torch.save(model.state_dict(), 'best.mdl')\n",
    "\n",
    "                viz.line([val_acc], [global_step], win='val_acc', update='append')\n",
    "print('best_acc:', best_acc,'best_epoch:', best_epoch)\n",
    "\n",
    "model.load_state_dict(torch.load('best.mdl'))\n",
    "test_acc = evalute(model, testLoader)\n",
    "print('test_acc:',test_acc)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = 224\n",
    "tf = transforms.Compose([\n",
    "            lambda x:Image.open(x).convert('RGB'), # string path= > image data\n",
    "            transforms.Resize((int(resize*1.25), int(resize*1.25))),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.CenterCrop(resize),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "img = tf('./data/pokemon/bulbasaur/00000001.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "pred = model(img.view(1,3,224,224)).argmax(dim=1)\n",
    "int(pred.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bulbasaur': 0, 'charmander': 1, 'mewtwo': 2, 'pikachu': 3, 'squirtle': 4}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.name2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl] *",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
